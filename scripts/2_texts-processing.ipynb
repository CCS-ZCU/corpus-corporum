{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c063b07f-73b4-4e0c-8e3f-e0c649f97d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language\n",
    "import pickle\n",
    "from unidecode import unidecode\n",
    "import sddk\n",
    "import pandas as pd\n",
    "import re\n",
    "import cupy\n",
    "import importlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c94c1b-ac1c-49da-a81a-ae8dbaaf22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "module_path = os.path.abspath(os.path.join(current_working_directory, '../../latin-preprocessing/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ef5fe2-a9cd-4aae-a2ac-effef44b40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try importing the module\n",
    "import tomela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "110c1bb3-8e71-4577-8ac8-693f68274c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case there is an update\n",
    "# importlib.reload(tomela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0b425-c2cb-448b-b672-f85d67b8f69d",
   "metadata": {},
   "source": [
    "## Extract sentence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45d58e33-d15d-4502-8b92-4448bdc323e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11862.txt',\n",
       " '15393.txt',\n",
       " '8089.txt',\n",
       " '20102.txt',\n",
       " '7275.txt',\n",
       " '10052.txt',\n",
       " '10765.txt',\n",
       " '7562.txt',\n",
       " '11896.txt',\n",
       " '9411.txt']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path = \"/srv/data/corpus-corporum/cc_rawtexts/\"\n",
    "filenames_list = os.listdir(source_path)\n",
    "filenames_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52ff0439-1304-4395-b26c-bc9ae133e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"/srv/data/corpus-corporum/cc_sents_jsons/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "62428d81-63ee-4cfc-9bf0-ecdaf208ad02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_ready = os.listdir(target_path)\n",
    "len(files_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a1c05-fdb2-4d33-a942-7afc7a24abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for n, filename in enumerate(filenames_list):\n",
    "    if filename not in files_ready:\n",
    "        id = filename.rpartition(\".txt\")[0]\n",
    "        with open(source_path + filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            rawtext = f.read()\n",
    "        doc = tomela.from_rawtext_to_doc(rawtext, lowertext=False)\n",
    "        doc_sentdata = [(sent.text, [(t.text, t.lemma_, t.pos_, (t.idx - sent[0].idx, t.idx - sent[0].idx + len(t))) for t in sent]) for sent in doc.sents]\n",
    "        #with open(target_path + id + \".pickle\", \"wb\") as f:\n",
    "        #    pickle.dump(doc_sentdata, f)\n",
    "        sent_data_updated = []\n",
    "        for n, sent_data in enumerate(doc_sentdata):\n",
    "            sent_data_updated.append((id, n, sent_data[0], sent_data[1]))\n",
    "        with open(target_path + id + \".json\", \"w\") as f:\n",
    "            json.dump(sent_data_updated, f)\n",
    "        if n in range(0, len(filenames_list), 50): # print out the progress each 50 files...\n",
    "            print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f60c10a-e668-48e4-8abd-ffc6ca42480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reading the data back with one file...\n",
    "fn = os.listdir(target_path)[0]\n",
    "sents_data = json.load(open(target_path + fn, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eccdac73-8182-4cec-8a28-a16a23ab21ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8089',\n",
       "  0,\n",
       "  'Benedictiones #benedictio in Annuntiatione sanctae Mariae.@# Dominus Jesus Christus, qui in saeculorum fine processit ex Uirgine, cor uestrum uirginitatis incorruptae corona clarificet.',\n",
       "  [['Benedictiones', 'benedictio', 'NOUN', [0, 13]],\n",
       "   ['#', '#', 'PUNCT', [14, 15]],\n",
       "   ['benedictio', 'benedictio', 'NOUN', [15, 25]],\n",
       "   ['in', 'in', 'ADP', [26, 28]],\n",
       "   ['Annuntiatione', 'annuntiatio', 'NOUN', [29, 42]],\n",
       "   ['sanctae', 'sanctus', 'ADJ', [43, 50]],\n",
       "   ['Mariae.@', 'Mariae.@', 'ADJ', [51, 59]],\n",
       "   ['#', '#', 'PUNCT', [59, 60]],\n",
       "   ['Dominus', 'Dominus', 'NOUN', [61, 68]],\n",
       "   ['Jesus', 'Jesus', 'PROPN', [69, 74]],\n",
       "   ['Christus', 'Christus', 'PROPN', [75, 83]],\n",
       "   [',', ',', 'PUNCT', [83, 84]],\n",
       "   ['qui', 'qui', 'PRON', [85, 88]],\n",
       "   ['in', 'in', 'ADP', [89, 91]],\n",
       "   ['saeculorum', 'saeculum', 'NOUN', [92, 102]],\n",
       "   ['fine', 'finis', 'NOUN', [103, 107]],\n",
       "   ['processit', 'procedo', 'VERB', [108, 117]],\n",
       "   ['ex', 'ex', 'ADP', [118, 120]],\n",
       "   ['Uirgine', 'uirgo', 'PROPN', [121, 128]],\n",
       "   [',', ',', 'PUNCT', [128, 129]],\n",
       "   ['cor', 'cor', 'NOUN', [130, 133]],\n",
       "   ['uestrum', 'tu', 'DET', [134, 141]],\n",
       "   ['uirginitatis', 'uirginitas', 'NOUN', [142, 154]],\n",
       "   ['incorruptae', 'incorruptus', 'ADJ', [155, 166]],\n",
       "   ['corona', 'corona', 'NOUN', [167, 173]],\n",
       "   ['clarificet', 'clarifico', 'VERB', [174, 184]],\n",
       "   ['.', '.', 'PUNCT', [184, 185]]]],\n",
       " ['8089',\n",
       "  1,\n",
       "  'Amen.',\n",
       "  [['Amen', 'amen', 'INTJ', [0, 4]], ['.', '.', 'PUNCT', [4, 5]]]],\n",
       " ['8089',\n",
       "  2,\n",
       "  'Et qui annuntiante angelo Uirginis ingressus est uterum, ejus uos ministerii et instruat et muniat sacramento.',\n",
       "  [['Et', 'et', 'CCONJ', [0, 2]],\n",
       "   ['qui', 'qui', 'PRON', [3, 6]],\n",
       "   ['annuntiante', 'annuntians', 'VERB', [7, 18]],\n",
       "   ['angelo', 'angelus', 'NOUN', [19, 25]],\n",
       "   ['Uirginis', 'uirgo', 'NOUN', [26, 34]],\n",
       "   ['ingressus', 'ingressus', 'VERB', [35, 44]],\n",
       "   ['est', 'sum', 'AUX', [45, 48]],\n",
       "   ['uterum', 'uterum', 'NOUN', [49, 55]],\n",
       "   [',', ',', 'PUNCT', [55, 56]],\n",
       "   ['ejus', 'ejus', 'DET', [57, 61]],\n",
       "   ['uos', 'uos', 'PRON', [62, 65]],\n",
       "   ['ministerii', 'ministerium', 'NOUN', [66, 76]],\n",
       "   ['et', 'et', 'CCONJ', [77, 79]],\n",
       "   ['instruat', 'instruo', 'VERB', [80, 88]],\n",
       "   ['et', 'et', 'CCONJ', [89, 91]],\n",
       "   ['muniat', 'munio', 'VERB', [92, 98]],\n",
       "   ['sacramento', 'sacramentum', 'NOUN', [99, 109]],\n",
       "   ['.', '.', 'PUNCT', [109, 110]]]],\n",
       " ['8089',\n",
       "  3,\n",
       "  'Amen.',\n",
       "  [['Amen', 'amen', 'INTJ', [0, 4]], ['.', '.', 'PUNCT', [4, 5]]]],\n",
       " ['8089',\n",
       "  4,\n",
       "  'Quique hodie Uirginis Conceptionem deuotissime celebratis, ad Natiuitatem nostri Redemptoris exsultantibus animis et mundo corde perueniatis.',\n",
       "  [['Quique', 'quisque', 'DET', [0, 6]],\n",
       "   ['hodie', 'hodie', 'ADV', [7, 12]],\n",
       "   ['Uirginis', 'uirgo', 'NOUN', [13, 21]],\n",
       "   ['Conceptionem', 'conceptio', 'NOUN', [22, 34]],\n",
       "   ['deuotissime', 'deuote', 'ADV', [35, 46]],\n",
       "   ['celebratis', 'celebro', 'VERB', [47, 57]],\n",
       "   [',', ',', 'PUNCT', [57, 58]],\n",
       "   ['ad', 'ad', 'ADP', [59, 61]],\n",
       "   ['Natiuitatem', 'natiuitas', 'NOUN', [62, 73]],\n",
       "   ['nostri', 'noster', 'DET', [74, 80]],\n",
       "   ['Redemptoris', 'redemptor', 'PROPN', [81, 92]],\n",
       "   ['exsultantibus', 'exsulto', 'VERB', [93, 106]],\n",
       "   ['animis', 'animus', 'NOUN', [107, 113]],\n",
       "   ['et', 'et', 'CCONJ', [114, 116]],\n",
       "   ['mundo', 'mundus', 'NOUN', [117, 122]],\n",
       "   ['corde', 'cor', 'NOUN', [123, 128]],\n",
       "   ['perueniatis', 'peruenio', 'VERB', [129, 140]],\n",
       "   ['.', '.', 'PUNCT', [140, 141]]]]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecea43d-8f1b-4ee4-867b-54e0b45e1f24",
   "metadata": {},
   "source": [
    "## Extract lemmatized & filtered sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b3e40df-9cef-49e0-b737-c1d7e8f78184",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = target_path\n",
    "target_path = \"/srv/data/corpus-corporum/cc_lemmatized_sents/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e836d69-9f24-4213-99ae-72a4e6d17f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/data/corpus-corporum/cc_sents_jsons/'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45bc1f9d-d582-49a4-ad84-77ec787306ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8089.json', '11862.json', '15393.json', '20102.json', '7275.json']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = os.listdir(source_path)\n",
    "fns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "923a1d06-0f64-44d6-9d5d-d2352fda947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in fns:\n",
    "    lemmatized_sents = []\n",
    "    with open(os.path.join(source_path, fn), \"r\") as file:\n",
    "        sents_data = json.load(file)\n",
    "        for (doc_id, sent_id, sent_text, sent_data) in sents_data:\n",
    "            lemmasent = []\n",
    "            for wordform, lemma, tag, position in sent_data:\n",
    "                if tag in [\"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]:\n",
    "                    lemmasent.append(lemma)\n",
    "            lemmatized_sents.append(\" \".join(lemmasent) + \"\\n\")\n",
    "\n",
    "    with open(os.path.join(target_path, fn.replace(\".json\", \".txt\")), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(lemmatized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95745462-de97-4dbb-a4fa-326710ef870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11862.txt'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(target_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1b58ce6-a337-4acd-9f14-b5da775e2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(target_path, os.listdir(target_path)[0]), \"r\", encoding=\"utf-8\") as f:\n",
    "    lemmatized_sents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27ebcc6a-bdda-409e-a82d-3a1006829ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decem categoria Capas\\n',\n",
       " 'scientia disciplina ars diuersus oratio tracto filum quiuis genus polleo inuenio oratio uolo origo tracto mirandus Aristoteles philosopeh diligentia disserendo cupidus coepio examen scio praetermitto necessarius\\n',\n",
       " '\\n',\n",
       " 'doceo grammaticus pars oratio uoco appello oratio pars indico uocabulum signo\\n',\n",
       " 'oratio pars auctor Aristoteles nomen uerbum debeo accipio caeterus facio compago oratio pars debeo nomino\\n',\n",
       " 'nomen persona demonstro uerbum facio patior\\n',\n",
       " 'Capitulum\\n',\n",
       " 'doceo debeo aduerto compendium oratio coarto gradus uocabulum capio concluseo\\n',\n",
       " 'diuersus innumerabilis mortalis nuncupatio comprehendo possum nomen latus diuersitas uocabulum homo dico nosco\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bbcce-34d3-40f0-8375-cca2fd9cac50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latin_global_kernel",
   "language": "python",
   "name": "latin_global_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
